#3种注入方式
helloWorld=spring Boot,\u4F60\u597D,--linzlb~
linzlb.a=a
linzlb.b=b

#将这个写到linzlb的配置文件中，不要放在application的配置文件
#linzlbproperties.x=x
#linzlbproperties.y=y
#linzlbproperties.z=z

#数据库连接配置，使用jpa
spring.datasource.url=jdbc:mysql://localhost:3306/db_springbootandcloud?serverTimezone=UTC&useUnicode=true&characterEncoding=utf-8&useSSL=true
spring.datasource.username=root
spring.datasource.password=123456
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
# 初始化时建立物理连接的个数。初始化发生在显示调用init方法，或者第一次getConnection时
spring.datasource.initial-size=10
# 最大连接池连接数量，最大活跃连接数
spring.datasource.max-active=150
# 最小连接池连接数量，最小空闲数量
spring.datasource.min-idle=10
# 配置获取连接等待超时的时间
spring.datasource.max-wait=5000
# 是否缓存preparedStatement，也就是PSCache。PSCache对支持游标的数据库性能提升巨大，比如说oracle。在mysql下建议关闭。
spring.datasource.pool-prepared-statements=false

spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=true

mybatis.type-aliases-package=com.linzlb.mapper
mybatis.mapper-locations=classpath:mapper/*.xml

#Spring Boot 提供了对 Redis 集成的组件包：spring-boot-starter-data-redis，\
#spring-boot-starter-data-redis依赖于spring-data-redis 和 lettuce 。\
#Spring Boot 1.0 默认使用的是 Jedis 客户端，2.0 替换成 Lettuce，\
#但如果你从 Spring Boot 1.5.X 切换过来，几乎感受不大差异，这是因为 spring-boot-starter-data-redis 为我们隔离了其中的差异性。
#Lettuce 是一个可伸缩线程安全的 Redis 客户端，多个线程可以共享同一个 RedisConnection，它利用优秀 netty NIO 框架来高效地管理多个连接。
# Redis数据库索引（默认为0）
spring.redis.database=0  
# Redis服务器地址
spring.redis.host=127.0.0.1
# Redis服务器连接端口
spring.redis.port=6379
# Redis服务器连接密码（默认为空）
spring.redis.password=
# 连接池最大连接数（使用负值表示没有限制） 默认 8
spring.redis.lettuce.pool.max-active=8
# 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1
spring.redis.lettuce.pool.max-wait=-1
# 连接池中的最大空闲连接 默认 8
spring.redis.lettuce.pool.max-idle=8
# 连接池中的最小空闲连接 默认 0
spring.redis.lettuce.pool.min-idle=0
spring.redis.timeout=0


#actuator配置 Start
#通过 http://localhost:8888/actuator/health 可以查看应用状态，通过 http://localhost:8888/actuator/info 查看info信息
#Spring Boot Actuator 提供了对单个 Spring Boot 的监控，信息包含：应用状态、内存、线程、堆栈等等，比较全面的监控了 Spring Boot 应用的整个生命周期。
#Actuator 提供了 13 个接口，具体如下表所示。
#HTTP 方法	路径	描述
#GET	/auditevents	显示应用暴露的审计事件 (比如认证进入、订单失败)
#GET	/beans	描述应用程序上下文里全部的 Bean，以及它们的关系
#GET	/conditions	就是 1.0 的 /autoconfig ，提供一份自动配置生效的条件情况，记录哪些自动配置条件通过了，哪些没通过
#GET	/configprops	描述配置属性(包含默认值)如何注入Bean
#GET	/env	获取全部环境属性
#GET	/env/{name}	根据名称获取特定的环境属性值
#GET	/flyway	提供一份 Flyway 数据库迁移信息
#GET	/liquidbase	显示Liquibase 数据库迁移的纤细信息
#GET	/health	报告应用程序的健康指标，这些值由 HealthIndicator 的实现类提供
#GET	/heapdump	dump 一份应用的 JVM 堆信息
#GET	/httptrace	显示HTTP足迹，最近100个HTTP request/repsponse
#GET	/info	获取应用程序的定制信息，这些信息由info打头的属性提供
#GET	/logfile	返回log file中的内容(如果 logging.file 或者 logging.path 被设置)
#GET	/loggers	显示和修改配置的loggers
#GET	/metrics	报告各种应用程序度量信息，比如内存用量和HTTP请求计数
#GET	/metrics/{name}	报告指定名称的应用程序度量值
#GET	/scheduledtasks	展示应用中的定时任务信息
#GET	/sessions	如果我们使用了 Spring Session 展示应用中的 HTTP sessions 信息
#POST	/shutdown	关闭应用程序，要求endpoints.shutdown.enabled设置为true
#GET	/mappings	描述全部的 URI路径，以及它们和控制器(包含Actuator端点)的映射关系
#GET	/threaddump	获取线程活动的快照
info.app.name=spring-boot-actuator
info.app.version= 1.0.0
info.app.test=test
#打开所有的监控点
management.endpoints.web.exposure.include=*
management.endpoint.health.show-details=always
#表启用单独的url地址来监控 Spring Boot 应用，为了安全一般都启用独立的端口来访问后端的监控信息
#management.endpoints.web.base-path=/monitor
#启用接口关闭 Spring Boot
management.endpoint.shutdown.enabled=true
#actuator配置 End




#kafka
###########【Kafka集群】  ,分隔###########
spring.kafka.bootstrap-servers=127.0.0.1:9092
###########【初始化生产者配置】###########
# 重试次数
spring.kafka.producer.retries=0
# 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
spring.kafka.producer.acks=1
# 批量大小
spring.kafka.producer.batch-size=16384
# 提交延时
spring.kafka.producer.properties.linger.ms=0
# 当生产端积累的消息达到batch-size或接收到消息linger.ms后,生产者就会将消息提交给kafka
# linger.ms为0表示每接收到一条消息就提交给kafka,这时候batch-size其实就没用了
​
# 生产端缓冲区大小
spring.kafka.producer.buffer-memory = 33554432
# Kafka提供的序列化和反序列化类
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
# 自定义分区器
# spring.kafka.producer.properties.partitioner.class=com.felix.kafka.producer.CustomizePartitioner
​
###########【初始化消费者配置】###########
# 默认的消费组ID
spring.kafka.consumer.properties.group.id=defaultConsumerGroup
# 是否自动提交offset
spring.kafka.consumer.enable-auto-commit=true
# 提交offset延时(接收到消息后多久提交offset)
spring.kafka.consumer.auto.commit.interval.ms=1000
# 当kafka中没有初始offset或offset超出范围时将自动重置offset
# earliest:重置为分区中最小的offset;
# latest:重置为分区中最新的offset(消费分区中新产生的数据);
# none:只要有一个分区不存在已提交的offset,就抛出异常;
spring.kafka.consumer.auto-offset-reset=latest
# 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
spring.kafka.consumer.properties.session.timeout.ms=120000
# 消费请求超时时间
spring.kafka.consumer.properties.request.timeout.ms=180000
# Kafka提供的序列化和反序列化类
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# 消费端监听的topic不存在时，项目启动会报错(关掉)
spring.kafka.listener.missing-topics-fatal=false
# 设置批量消费
# spring.kafka.listener.type=batch
# 批量消费每次最多消费多少条消息
# spring.kafka.consumer.max-poll-records=50